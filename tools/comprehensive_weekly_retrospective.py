#!/usr/bin/env python3
"""
Comprehensive Weekly Retrospective - íˆ¬ëª…í•˜ê³  ê°•ë ¥í•œ íšŒê³  ì‹œìŠ¤í…œ

í†µí•© ìš”ì†Œ:
1. Karpathyì˜ 4ê°€ì§€ ì›ì¹™ (Think, Simplicity, Surgical, Goal-Driven)
2. Bitter Lesson (í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ > ì–‘, í•™ìŠµ ê°€ëŠ¥í•œ êµ¬ì¡°)
3. ì „ì—­ ë°ì´í„° ìˆ˜ì§‘ (Claude Code, Codex, Git, Browser, Terminal)
4. íŒ¨í„´ ì¸ì‚¬ì´íŠ¸ + ë©”íƒ€ íšŒê³ 
"""

import json
import sys
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List
from collections import Counter

__version__ = "1.0.0"

TOOL_SPEC = {
    "name": "comprehensive_weekly_retrospective",
    "description": "Karpathy ì›ì¹™ + Bitter Lesson ê¸°ë°˜ íˆ¬ëª…í•œ ì£¼ê°„ íšŒê³ ",
    "version": "1.0.0",
    "input_schema": {
        "type": "object",
        "properties": {
            "days_back": {
                "type": "integer",
                "description": "íšŒê³  ê¸°ê°„ (ì¼)",
                "default": 7
            },
            "output_format": {
                "type": "string",
                "enum": ["markdown", "json"],
                "description": "ì¶œë ¥ í˜•ì‹",
                "default": "markdown"
            }
        }
    }
}


def collect_git_commits(days_back: int, workdir: str) -> List[Dict[str, Any]]:
    """Git ì»¤ë°‹ ìˆ˜ì§‘"""
    commits = []
    since = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")

    try:
        result = subprocess.run(
            ["git", "log", f"--since={since}", "--pretty=format:%H|%ad|%s|%an", "--date=iso"],
            cwd=workdir,
            capture_output=True,
            text=True,
            timeout=10
        )

        for line in result.stdout.strip().split('\n'):
            if line:
                parts = line.split('|', 3)
                if len(parts) == 4:
                    commits.append({
                        "hash": parts[0][:7],
                        "date": parts[1][:10],
                        "time": parts[1][11:19],
                        "message": parts[2],
                        "author": parts[3]
                    })
    except Exception:
        pass

    return commits


def analyze_karpathy_principles(prompts: List[Dict], commits: List[Dict]) -> Dict[str, Any]:
    """Karpathy 4ê°€ì§€ ì›ì¹™ ë¶„ì„"""

    # 1. Think Before Coding (ê°€ì • vs ì§ˆë¬¸)
    questions = sum(1 for p in prompts if '?' in p.get('content', '') or any(
        word in p.get('content', '').lower()
        for word in ['ì–´ë–»ê²Œ', 'ì™œ', 'ë­', 'ë¬´ì—‡', 'ì–¸ì œ', 'how', 'why', 'what']
    ))
    assumptions = len(prompts) - questions
    think_score = min(100, int((questions / len(prompts)) * 150)) if prompts else 0

    # 2. Simplicity First (ì½”ë“œ ë³µì¡ë„)
    # ì»¤ë°‹ ë©”ì‹œì§€ì—ì„œ ë¦¬íŒ©í† ë§/ë‹¨ìˆœí™” í‚¤ì›Œë“œ ì°¾ê¸°
    simplification_commits = sum(1 for c in commits if any(
        word in c['message'].lower()
        for word in ['ë¦¬íŒ©í† ë§', 'ë‹¨ìˆœí™”', 'ì •ë¦¬', 'refactor', 'simplify', 'clean']
    ))
    simplicity_score = min(100, int((simplification_commits / max(len(commits), 1)) * 200))

    # 3. Surgical Changes (ë³€ê²½ ë²”ìœ„)
    # ì‘ì€ ì»¤ë°‹ì´ ì¢‹ì€ ì»¤ë°‹ (ë©”ì‹œì§€ ê¸¸ì´ë¡œ ì¶”ì •)
    avg_commit_msg_length = sum(len(c['message']) for c in commits) / max(len(commits), 1) if commits else 0
    surgical_score = 100 if 20 <= avg_commit_msg_length <= 80 else 50

    # 4. Goal-Driven (ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ)
    # êµ¬ì²´ì  ëª©í‘œê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸/ì»¤ë°‹ (ìˆ«ì, í…ŒìŠ¤íŠ¸, ì™„ë£Œ ë“±)
    goal_keywords = ['í…ŒìŠ¤íŠ¸', 'ì™„ë£Œ', 'ì„±ê³µ', 'ë‹¬ì„±', 'ëª©í‘œ', 'test', 'pass', 'complete', 'done']
    goal_driven_count = sum(1 for p in prompts if any(
        word in p.get('content', '').lower() for word in goal_keywords
    ))
    goal_score = min(100, int((goal_driven_count / max(len(prompts), 1)) * 300))

    return {
        "think_before_coding": {
            "score": think_score,
            "questions": questions,
            "assumptions": assumptions,
            "advice": "âœ… ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ ë¹„ìœ¨ ì¢‹ìŒ" if think_score >= 70 else "âš ï¸ ê°€ì •ë³´ë‹¤ ì§ˆë¬¸í•˜ê¸°"
        },
        "simplicity_first": {
            "score": simplicity_score,
            "refactoring_commits": simplification_commits,
            "advice": "âœ… ë‹¨ìˆœí™” ì‘ì—… ì§„í–‰ ì¤‘" if simplicity_score >= 50 else "âš ï¸ ë³µì¡ë„ ì¤„ì´ê¸°"
        },
        "surgical_changes": {
            "score": surgical_score,
            "avg_commit_size": f"{avg_commit_msg_length:.1f}ì",
            "advice": "âœ… ì ì ˆí•œ ì»¤ë°‹ í¬ê¸°" if surgical_score >= 70 else "âš ï¸ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ì»¤ë°‹"
        },
        "goal_driven": {
            "score": goal_score,
            "goal_oriented_prompts": goal_driven_count,
            "advice": "âœ… ëª©í‘œ ì§€í–¥ì " if goal_score >= 60 else "âš ï¸ ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ ì„¤ì •"
        },
        "overall_score": int((think_score + simplicity_score + surgical_score + goal_score) / 4)
    }


def analyze_bitter_lesson(prompts: List[Dict], prev_week_prompts: List[Dict]) -> Dict[str, Any]:
    """Bitter Lesson ë¶„ì„ (í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ > ì–‘)"""

    # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í†µê³„
    lengths = [len(p.get('content', '')) for p in prompts]
    avg_length = sum(lengths) / len(lengths) if lengths else 0

    # í’ˆì§ˆ ì§€í‘œ
    quality_indicators = {
        "ê¸¸ì´ ì ì •": 30 <= avg_length <= 200,
        "êµ¬ì²´ì ": sum(1 for p in prompts if len(p.get('content', '').split()) > 10) / max(len(prompts), 1) > 0.5,
        "ë§¥ë½ ì œê³µ": sum(1 for p in prompts if any(
            word in p.get('content', '').lower()
            for word in ['ë•Œë¬¸ì—', 'ìœ„í•´', 'í•˜ë ¤ê³ ', 'because', 'to', 'for']
        )) / max(len(prompts), 1) > 0.3
    }

    quality_score = sum(1 for v in quality_indicators.values() if v) * 33.3

    # ì „ì£¼ ëŒ€ë¹„ í’ˆì§ˆ ê°œì„ 
    prev_avg_length = sum(len(p.get('content', '')) for p in prev_week_prompts) / max(len(prev_week_prompts), 1) if prev_week_prompts else 0
    quality_trend = "ğŸ“ˆ ê°œì„ " if avg_length > prev_avg_length else "ğŸ“‰ ìœ ì§€" if avg_length == prev_avg_length else "ğŸ“‰ ì €í•˜"

    # ë²„ë ¤ì•¼ í•  ìŠ¤ìºí´ë”© ê°ì§€ (ë°˜ë³µë˜ëŠ” í”„ë¡¬í”„íŠ¸ íŒ¨í„´)
    prompt_texts = [p.get('content', '')[:50].lower() for p in prompts]
    repeated = [text for text, count in Counter(prompt_texts).items() if count > 3]

    return {
        "quality_score": int(quality_score),
        "avg_prompt_length": f"{avg_length:.1f}ì",
        "quality_indicators": quality_indicators,
        "quality_trend": quality_trend,
        "repeated_patterns": repeated[:3],  # ìƒìœ„ 3ê°œ
        "advice": [
            "âœ… í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ìš°ìˆ˜" if quality_score >= 70 else "âš ï¸ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ê°œì„  í•„ìš”",
            f"í‰ê·  ê¸¸ì´ {avg_length:.0f}ì {'ì ì •' if 30 <= avg_length <= 200 else 'ì¡°ì • í•„ìš”'}",
            f"ë°˜ë³µ íŒ¨í„´ {len(repeated)}ê°œ ë°œê²¬ â†’ ìë™í™” ê³ ë ¤" if repeated else "âœ… íŒ¨í„´ ë°˜ë³µ ì—†ìŒ"
        ]
    }


def generate_insights(data: Dict[str, Any]) -> List[str]:
    """íŒ¨í„´ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []

    prompts = data.get('prompts', [])
    commits = data.get('commits', [])

    # í”„ë¡¬í”„íŠ¸ ì†ŒìŠ¤ ë¶„í¬
    sources = Counter(p.get('source') for p in prompts)
    if sources:
        main_source = sources.most_common(1)[0]
        insights.append(f"ğŸ¯ ì£¼ë ¥ ë„êµ¬: {main_source[0]} ({main_source[1]}ê°œ, {main_source[1]/len(prompts)*100:.1f}%)")

    # ì»¤ë°‹ ì§‘ì¤‘ë„
    if commits:
        commit_dates = Counter(c['date'] for c in commits)
        if len(commit_dates) == 1:
            insights.append("âš ï¸ ëª¨ë“  ì»¤ë°‹ì´ í•˜ë£¨ì— ì§‘ì¤‘ â†’ ë¶„ì‚° ê¶Œì¥")
        elif len(commit_dates) >= 5:
            insights.append("âœ… ì»¤ë°‹ì´ ì—¬ëŸ¬ ë‚ ì— ë¶„ì‚° â†’ ê¾¸ì¤€í•œ ì‘ì—…")

    # í”„ë¡¬í”„íŠ¸ íƒ€ì… ê· í˜•
    question_count = sum(1 for p in prompts if '?' in p.get('content', ''))
    command_count = sum(1 for p in prompts if 'í•´ì¤˜' in p.get('content', '') or 'ë§Œë“¤ì–´' in p.get('content', ''))

    if question_count > command_count * 2:
        insights.append("ğŸ’¡ ì§ˆë¬¸í˜•ì´ ë§ìŒ â†’ íƒìƒ‰/í•™ìŠµ ë‹¨ê³„")
    elif command_count > question_count * 2:
        insights.append("ğŸ”¨ ì§€ì‹œí˜•ì´ ë§ìŒ â†’ ì‹¤í–‰ ë‹¨ê³„")
    else:
        insights.append("âœ… ì§ˆë¬¸í˜•/ì§€ì‹œí˜• ê· í˜•")

    # í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì¶”ì´
    karpathy = data.get('karpathy_analysis', {})
    overall = karpathy.get('overall_score', 0)
    if overall >= 80:
        insights.append("ğŸ† Karpathy ì›ì¹™ ì¤€ìˆ˜ ìš°ìˆ˜")
    elif overall >= 60:
        insights.append("ğŸ“Š Karpathy ì›ì¹™ ì¤€ìˆ˜ ì–‘í˜¸")
    else:
        insights.append("âš ï¸ Karpathy ì›ì¹™ ê°œì„  í•„ìš”")

    return insights


def generate_next_week_goals(data: Dict[str, Any]) -> List[Dict[str, str]]:
    """ë‹¤ìŒ ì£¼ SMART ëª©í‘œ ìƒì„±"""
    goals = []

    prompts = data.get('prompts', [])
    commits = data.get('commits', [])
    karpathy = data.get('karpathy_analysis', {})
    bitter = data.get('bitter_lesson_analysis', {})

    # Goal 1: ì»¤ë°‹ ëª©í‘œ
    current_commits = len(commits)
    target_commits = max(10, int(current_commits * 1.5))
    goals.append({
        "area": "ì½”ë”©",
        "goal": f"ì»¤ë°‹ {target_commits}ê°œ ì´ìƒ (í˜„ì¬ {current_commits}ê°œ)",
        "metric": f"git log --since='1 week ago' | grep '^commit' | wc -l >= {target_commits}"
    })

    # Goal 2: í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ
    quality_score = bitter.get('quality_score', 0)
    if quality_score < 70:
        goals.append({
            "area": "í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ",
            "goal": "í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì ìˆ˜ 70ì  ì´ìƒ",
            "metric": "í‰ê·  ê¸¸ì´ 30-200ì, ë§¥ë½ ì œê³µ, êµ¬ì²´ì "
        })

    # Goal 3: Karpathy ì›ì¹™
    if karpathy.get('overall_score', 0) < 80:
        weak_principle = min(
            karpathy.items(),
            key=lambda x: x[1].get('score', 100) if isinstance(x[1], dict) else 100
        )
        goals.append({
            "area": "ì½”ë”© ì›ì¹™",
            "goal": f"{weak_principle[0]} ê°œì„ ",
            "metric": f"{weak_principle[1].get('advice', '')}"
        })

    # Goal 4: ê· í˜•
    goals.append({
        "area": "ì‘ì—… ë¶„ì‚°",
        "goal": "ë§¤ì¼ ìµœì†Œ 1ì»¤ë°‹",
        "metric": "ì—°ì† 7ì¼ ì»¤ë°‹ ê¸°ë¡"
    })

    return goals[:3]  # ìƒìœ„ 3ê°œë§Œ


def run(input_data: dict, context: dict) -> dict:
    """ì¢…í•© ì£¼ê°„ íšŒê³  ì‹¤í–‰"""
    days_back = input_data.get("days_back", 7)
    output_format = input_data.get("output_format", "markdown")
    workdir = context.get("workdir", ".")

    # 1. ë°ì´í„° ìˆ˜ì§‘
    print("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", file=sys.stderr)

    # í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘ (ì˜¤ëŠ˜ íŒŒì¼)
    today = datetime.now().strftime("%Y%m%d")
    prompts_file = Path(workdir) / "logs" / f"prompts_collected_{today}.jsonl"

    prompts = []
    if prompts_file.exists():
        with open(prompts_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    prompts.append(json.loads(line))
                except json.JSONDecodeError:
                    continue

    # Git ì»¤ë°‹
    commits = collect_git_commits(days_back, workdir)

    # ì „ì£¼ í”„ë¡¬í”„íŠ¸ (ë¹„êµìš©)
    prev_week_file = Path(workdir) / "logs" / f"prompts_collected_{(datetime.now() - timedelta(days=7)).strftime('%Y%m%d')}.jsonl"
    prev_prompts = []
    if prev_week_file.exists():
        with open(prev_week_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    prev_prompts.append(json.loads(line))
                except json.JSONDecodeError:
                    continue

    # 2. ë¶„ì„
    print("ğŸ§  ë¶„ì„ ì¤‘...", file=sys.stderr)

    karpathy_analysis = analyze_karpathy_principles(prompts, commits)
    bitter_lesson_analysis = analyze_bitter_lesson(prompts, prev_prompts)

    data = {
        "prompts": prompts,
        "commits": commits,
        "karpathy_analysis": karpathy_analysis,
        "bitter_lesson_analysis": bitter_lesson_analysis
    }

    insights = generate_insights(data)
    next_week_goals = generate_next_week_goals(data)

    # 3. ì¶œë ¥ ìƒì„±
    if output_format == "json":
        return {
            "success": True,
            "period": f"{days_back}ì¼",
            "total_prompts": len(prompts),
            "total_commits": len(commits),
            "karpathy_analysis": karpathy_analysis,
            "bitter_lesson_analysis": bitter_lesson_analysis,
            "insights": insights,
            "next_week_goals": next_week_goals
        }

    # Markdown ì¶œë ¥
    lines = []
    lines.append(f"# ì£¼ê°„ íšŒê³  ({datetime.now().strftime('%Y-%m-%d')})")
    lines.append("")
    lines.append(f"> **Karpathy ì›ì¹™ + Bitter Lesson ê¸°ë°˜ íˆ¬ëª…í•œ íšŒê³ **")
    lines.append("")

    # Part 1: Raw Data
    lines.append("## ğŸ“Š Part 1: Raw Data (íˆ¬ëª…ì„±)")
    lines.append("")
    lines.append(f"**ê¸°ê°„**: ìµœê·¼ {days_back}ì¼")
    lines.append(f"**í”„ë¡¬í”„íŠ¸**: {len(prompts)}ê°œ")
    lines.append(f"**ì»¤ë°‹**: {len(commits)}ê°œ")
    lines.append("")

    # í”„ë¡¬í”„íŠ¸ ì†ŒìŠ¤ë³„
    sources = Counter(p.get('source') for p in prompts)
    lines.append("**í”„ë¡¬í”„íŠ¸ ì†ŒìŠ¤**:")
    for source, count in sources.most_common():
        lines.append(f"- {source}: {count}ê°œ ({count/len(prompts)*100:.1f}%)")
    lines.append("")

    # Part 2: Karpathy ë¶„ì„
    lines.append("## ğŸ¯ Part 2: Karpathy ì›ì¹™ ë¶„ì„")
    lines.append("")
    lines.append(f"**ì¢…í•© ì ìˆ˜**: {karpathy_analysis['overall_score']}/100")
    lines.append("")

    for principle, details in karpathy_analysis.items():
        if principle == 'overall_score':
            continue
        if isinstance(details, dict):
            lines.append(f"### {principle.replace('_', ' ').title()}")
            lines.append(f"- **ì ìˆ˜**: {details['score']}/100")
            lines.append(f"- **ì¡°ì–¸**: {details['advice']}")
            lines.append("")

    # Part 3: Bitter Lesson
    lines.append("## ğŸ’¡ Part 3: Bitter Lesson ë¶„ì„")
    lines.append("")
    lines.append(f"**í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì ìˆ˜**: {bitter_lesson_analysis['quality_score']}/100")
    lines.append(f"**í‰ê·  ê¸¸ì´**: {bitter_lesson_analysis['avg_prompt_length']}")
    lines.append(f"**í’ˆì§ˆ ì¶”ì´**: {bitter_lesson_analysis['quality_trend']}")
    lines.append("")
    lines.append("**ì¡°ì–¸**:")
    for advice in bitter_lesson_analysis['advice']:
        lines.append(f"- {advice}")
    lines.append("")

    # Part 4: ì¸ì‚¬ì´íŠ¸
    lines.append("## ğŸ” Part 4: íŒ¨í„´ ì¸ì‚¬ì´íŠ¸")
    lines.append("")
    for insight in insights:
        lines.append(f"- {insight}")
    lines.append("")

    # Part 5: ë‹¤ìŒ ì£¼ ëª©í‘œ
    lines.append("## ğŸ¯ Part 5: ë‹¤ìŒ ì£¼ SMART ëª©í‘œ")
    lines.append("")
    for i, goal in enumerate(next_week_goals, 1):
        lines.append(f"### Goal {i}: {goal['area']}")
        lines.append(f"- **ëª©í‘œ**: {goal['goal']}")
        lines.append(f"- **ì¸¡ì •**: {goal['metric']}")
        lines.append("")

    # Part 6: ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
    lines.append("## âœ… Part 6: ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸")
    lines.append("")
    lines.append("**ì´ë²ˆ ì£¼ ì‹¤í–‰í•  ê²ƒ**:")
    lines.append("- [ ] ë§¤ì¼ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì²´í¬")
    lines.append("- [ ] Karpathy ì›ì¹™ ì ìš© (ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸)")
    lines.append("- [ ] ì‘ì€ ë‹¨ìœ„ë¡œ ì»¤ë°‹")
    lines.append("- [ ] ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ ì„¤ì •")
    lines.append("")

    markdown = "\n".join(lines)

    # íŒŒì¼ ì €ì¥
    output_file = Path(workdir) / f"weekly_retrospective_{datetime.now().strftime('%Y_week%W')}.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown)

    return {
        "success": True,
        "output_file": str(output_file),
        "markdown": markdown,
        "summary": {
            "prompts": len(prompts),
            "commits": len(commits),
            "karpathy_score": karpathy_analysis['overall_score'],
            "quality_score": bitter_lesson_analysis['quality_score']
        }
    }


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--tool-spec-json", action="store_true")
    parser.add_argument("--tool-input-json", type=str)
    parser.add_argument("--tool-context-json", type=str)

    args = parser.parse_args()

    if args.tool_spec_json:
        print(json.dumps(TOOL_SPEC, ensure_ascii=False, indent=2))
        sys.exit(0)

    input_data = json.loads(args.tool_input_json) if args.tool_input_json else {}
    context = json.loads(args.tool_context_json) if args.tool_context_json else {}

    result = run(input_data, context)
    print(json.dumps(result, ensure_ascii=False, indent=2))
