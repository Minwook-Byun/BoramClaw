#!/usr/bin/env python3
"""
study_tracker.py
16ì£¼ ML ì»¤ë¦¬í˜ëŸ¼ ì§„ë„ ì¶”ì  íˆ´

- í˜„ì¬ ì£¼ì°¨ ìë™ ê³„ì‚° (config/study_plan.json ê¸°ì¤€)
- Codex/Claude Code í”„ë¡¬í”„íŠ¸ì—ì„œ í•™ìŠµ í‚¤ì›Œë“œ íƒì§€
- ì¼ê°„/ì£¼ê°„ í•™ìŠµ ì¦ê±° ë ˆí¬íŠ¸ + ë¯¸ë‹¬ ì‹œ ê²½ê³ 
"""
import sys
import json
import argparse
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

__version__ = "1.0.0"

TOOL_SPEC = {
    "name": "study_tracker",
    "description": """16ì£¼ ML ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ì§„ë„ë¥¼ ì¶”ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

    ë§¤ì¼ íšŒê³ /ì£¼ê°„ íšŒê³  ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ì–´:
    - í˜„ì¬ ì£¼ì°¨ ë° ì´ë²ˆ ì£¼ í•™ìŠµ ì£¼ì œ í™•ì¸
    - Codex/Claude ëŒ€í™”ì—ì„œ í•™ìŠµ í‚¤ì›Œë“œ íƒì§€
    - í•™ìŠµ ì¦ê±°(í”„ë¡¬í”„íŠ¸) ìš”ì•½
    - ëª©í‘œ ë¯¸ë‹¬ ì‹œ ê²½ê³  ë° ê¶Œê³ ì‚¬í•­ ì œê³µ

    í•™ìŠµ ì¤‘ì¸ ë…¼ë¬¸: Attention â†’ Scaling Laws â†’ FlashAttention â†’ KV Cache
    â†’ LoRA â†’ QLoRA â†’ RLHF â†’ MoE â†’ vLLM â†’ ZeRO â†’ Tensor Parallel
    â†’ Cost Model â†’ RAG â†’ ReAct â†’ Toolformer â†’ AX Architecture
    """,
    "version": "1.0.0",
    "input_schema": {
        "type": "object",
        "properties": {
            "mode": {
                "type": "string",
                "enum": ["daily", "weekly"],
                "description": "daily=ì˜¤ëŠ˜ í•™ìŠµ ì²´í¬, weekly=ì´ë²ˆ ì£¼ ì „ì²´ ì§„ë„",
                "default": "daily"
            },
            "days_back": {
                "type": "integer",
                "description": "ëª‡ ì¼ì¹˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í• ì§€ (ê¸°ë³¸ê°’: daily=1, weekly=7)",
                "default": 1
            },
            "override_week": {
                "type": "integer",
                "description": "ì£¼ì°¨ ê°•ì œ ì§€ì • (í…ŒìŠ¤íŠ¸ìš©, ë³´í†µ ìë™ ê³„ì‚°)",
                "default": None
            }
        },
        "required": []
    }
}

# í•™ìŠµ ì¦ê±° ì„ê³„ê°’
MIN_STUDY_PROMPTS_DAILY = 3       # í•˜ë£¨ ìµœì†Œ í•™ìŠµ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜
MIN_STUDY_PROMPTS_WEEKLY = 15     # ì£¼ê°„ ìµœì†Œ í•™ìŠµ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜
STUDY_PLAN_PATH = Path(__file__).parent.parent / "config" / "study_plan.json"


def load_study_plan() -> Optional[Dict]:
    """study_plan.json ë¡œë“œ"""
    if not STUDY_PLAN_PATH.exists():
        return None
    try:
        return json.loads(STUDY_PLAN_PATH.read_text(encoding="utf-8"))
    except Exception:
        return None


def get_current_week_info(plan: Dict, override_week: Optional[int] = None) -> Dict:
    """
    ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ì£¼ì°¨ì™€ í•´ë‹¹ ì£¼ í•™ìŠµ ì •ë³´ ë°˜í™˜.
    ì•„ì§ ì‹œì‘ ì•ˆ ëê±°ë‚˜ ì»¤ë¦¬í˜ëŸ¼ ì™„ë£Œ ì‹œ ì ì ˆí•œ ë©”ì‹œì§€ ë°˜í™˜.
    """
    start_date = datetime.strptime(plan["start_date"], "%Y-%m-%d")
    today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

    if override_week:
        week_num = override_week
    else:
        delta = (today - start_date).days
        if delta < 0:
            days_until = -delta
            return {
                "status": "not_started",
                "message": f"ì»¤ë¦¬í˜ëŸ¼ì´ {plan['start_date']}ì— ì‹œì‘ë©ë‹ˆë‹¤ (D-{days_until})",
                "start_date": plan["start_date"],
                "week": 0
            }
        week_num = (delta // 7) + 1

    total_weeks = plan.get("total_weeks", 16)
    if week_num > total_weeks:
        return {
            "status": "completed",
            "message": f"ğŸ‰ 16ì£¼ ì»¤ë¦¬í˜ëŸ¼ ì™„ë£Œ! (ë§ˆì§€ë§‰ ì£¼: Week {total_weeks})",
            "week": week_num
        }

    # í•´ë‹¹ ì£¼ì°¨ì˜ ìƒì„¸ ì •ë³´ ì°¾ê¸°
    week_info = None
    phase_info = None
    for phase in plan.get("phases", []):
        for w in phase.get("weeks", []):
            if w["week"] == week_num:
                week_info = w
                phase_info = phase
                break
        if week_info:
            break

    if not week_info:
        return {"status": "unknown", "week": week_num}

    # í•´ë‹¹ ì£¼ ë‚ ì§œ ë²”ìœ„
    week_start = start_date + timedelta(weeks=week_num - 1)
    week_end = week_start + timedelta(days=6)

    return {
        "status": "active",
        "week": week_num,
        "phase": phase_info["phase"],
        "phase_name": phase_info["name"],
        "topic": week_info["topic"],
        "paper": week_info["paper"],
        "goal": week_info["goal"],
        "deliverable": week_info["deliverable"],
        "keywords": week_info["keywords"],
        "week_start": week_start.strftime("%Y-%m-%d"),
        "week_end": week_end.strftime("%Y-%m-%d"),
    }


def get_all_week_keywords(plan: Dict, up_to_week: int) -> Dict[int, List[str]]:
    """ì£¼ì°¨ë³„ í‚¤ì›Œë“œ ë§µ ë°˜í™˜ (ëˆ„ì  í•™ìŠµ ì²´í¬ìš©)"""
    result = {}
    for phase in plan.get("phases", []):
        for w in phase.get("weeks", []):
            if w["week"] <= up_to_week:
                result[w["week"]] = w["keywords"]
    return result


def collect_recent_prompts(days_back: int, workdir: str) -> List[Dict]:
    """ìµœê·¼ Nì¼ í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘ (prompts_collected_*.jsonl íŒŒì¼ì—ì„œ)"""
    prompts = []
    logs_dir = Path(workdir) / "logs"
    if not logs_dir.exists():
        return prompts

    cutoff = datetime.now() - timedelta(days=days_back)
    cutoff_str = cutoff.strftime("%Y-%m-%d")

    # ìµœê·¼ íŒŒì¼ë“¤ íƒìƒ‰
    for jsonl_file in sorted(logs_dir.glob("prompts_collected_*.jsonl"), reverse=True):
        try:
            with open(jsonl_file, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        p = json.loads(line.strip())
                        if p.get("date", "") >= cutoff_str:
                            prompts.append(p)
                    except json.JSONDecodeError:
                        continue
        except Exception:
            continue

    return prompts


def detect_study_prompts(
    prompts: List[Dict],
    keywords: List[str],
    week_topic: str
) -> Tuple[List[Dict], List[Dict]]:
    """
    í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•™ìŠµ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íƒì§€.
    Returns: (matched_prompts, high_quality_matches)
    """
    matched = []
    lower_keywords = [kw.lower() for kw in keywords]

    for p in prompts:
        content = (p.get("content", "") or p.get("full_content", "") or "").lower()
        if not content:
            continue

        # í‚¤ì›Œë“œ ë§¤ì¹­
        matched_kws = [kw for kw in lower_keywords if kw in content]
        if matched_kws:
            p_copy = dict(p)
            p_copy["_matched_keywords"] = matched_kws[:5]
            p_copy["_match_count"] = len(matched_kws)
            matched.append(p_copy)

    # ë§¤ì¹­ ìˆ˜ ê¸°ì¤€ ì •ë ¬ (ë§ì´ ë§¤ì¹­ë ìˆ˜ë¡ ë” ê´€ë ¨ì„± ë†’ìŒ)
    matched.sort(key=lambda x: x["_match_count"], reverse=True)

    # ê³ í’ˆì§ˆ ë§¤ì¹­: 2ê°œ ì´ìƒ í‚¤ì›Œë“œ ë§¤ì¹­ or ë‚´ìš©ì´ êµ¬ì²´ì 
    high_quality = [p for p in matched if p["_match_count"] >= 2 or len(p.get("content", "")) > 50]

    return matched, high_quality


def build_study_report(
    mode: str,
    week_info: Dict,
    prompts: List[Dict],
    days_back: int
) -> Dict:
    """í•™ìŠµ ì§„ë„ ë ˆí¬íŠ¸ ìƒì„±"""
    if week_info.get("status") != "active":
        return {
            "success": True,
            "status": week_info.get("status"),
            "message": week_info.get("message", ""),
            "week": week_info.get("week", 0)
        }

    week_num = week_info["week"]
    topic = week_info["topic"]
    keywords = week_info["keywords"]

    # Codex í”„ë¡¬í”„íŠ¸ë§Œ í•„í„° (í•™ìŠµì€ ì£¼ë¡œ Codexë¡œ)
    codex_prompts = [p for p in prompts if "codex" in str(p.get("source", "")).lower()]
    claude_prompts = [p for p in prompts if "claude" in str(p.get("source", "")).lower()]
    all_study_prompts = codex_prompts + claude_prompts

    matched, high_quality = detect_study_prompts(all_study_prompts, keywords, topic)

    # ì„ê³„ê°’ ë° ê²½ê³  ê³„ì‚°
    threshold = MIN_STUDY_PROMPTS_DAILY if mode == "daily" else MIN_STUDY_PROMPTS_WEEKLY
    period_label = "ì˜¤ëŠ˜" if mode == "daily" else "ì´ë²ˆ ì£¼"
    match_count = len(matched)
    hq_count = len(high_quality)

    # ê²½ê³  ë ˆë²¨ ê²°ì •
    if match_count == 0:
        warning_level = "ğŸ”´ CRITICAL"
        warning_msg = f"{period_label} {topic} ê´€ë ¨ í•™ìŠµ ê¸°ë¡ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. Codexì—ê²Œ ë…¼ë¬¸ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!"
    elif match_count < threshold // 2:
        warning_level = "ğŸŸ  WARNING"
        warning_msg = f"{period_label} í•™ìŠµëŸ‰ì´ ëª©í‘œì˜ {int(match_count / threshold * 100)}% ìˆ˜ì¤€ì…ë‹ˆë‹¤. ë” ì§ˆë¬¸í•´ë³´ì„¸ìš”."
    elif match_count < threshold:
        warning_level = "ğŸŸ¡ CAUTION"
        warning_msg = f"{period_label} {match_count}ê°œ ê°ì§€ (ëª©í‘œ: {threshold}ê°œ). ì¡°ê¸ˆ ë” íŒŒê³ ë“œì„¸ìš”."
    else:
        warning_level = "ğŸŸ¢ GOOD"
        warning_msg = f"{period_label} í•™ìŠµ ëª©í‘œ ë‹¬ì„±! ({match_count}ê°œ / ëª©í‘œ {threshold}ê°œ)"

    # ëŒ€í‘œ í•™ìŠµ í”„ë¡¬í”„íŠ¸ ìƒ˜í”Œ (ìµœëŒ€ 5ê°œ)
    sample_prompts = []
    for p in matched[:5]:
        sample_prompts.append({
            "source": p.get("source", "?"),
            "date": p.get("date", ""),
            "time": p.get("time", ""),
            "content": (p.get("content", "") or "")[:120],
            "matched_keywords": p.get("_matched_keywords", [])
        })

    # Codex ì¶”ì²œ ì§ˆë¬¸ (í•™ìŠµ í‚¤ì›Œë“œ ê¸°ë°˜)
    suggested_questions = _build_suggested_questions(topic, keywords, week_info)

    return {
        "success": True,
        "status": "active",
        "week": week_num,
        "phase": week_info["phase"],
        "phase_name": week_info["phase_name"],
        "topic": topic,
        "paper": week_info["paper"],
        "goal": week_info["goal"],
        "deliverable": week_info["deliverable"],
        "week_range": f"{week_info['week_start']} ~ {week_info['week_end']}",
        "study_evidence": {
            "total_matched": match_count,
            "high_quality_matched": hq_count,
            "threshold": threshold,
            "sample_prompts": sample_prompts
        },
        "warning": {
            "level": warning_level,
            "message": warning_msg
        },
        "suggested_questions": suggested_questions,
        "raw_prompt_count": {
            "codex": len(codex_prompts),
            "claude": len(claude_prompts),
            "total": len(all_study_prompts)
        }
    }


def _build_suggested_questions(topic: str, keywords: List[str], week_info: Dict) -> List[str]:
    """ì£¼ì œë³„ Codexì—ê²Œ ë¬¼ì–´ë³¼ ì¶”ì²œ ì§ˆë¬¸ ìƒì„±"""
    goal = week_info.get("goal", "")
    deliverable = week_info.get("deliverable", "")

    suggestions = {
        "Attention êµ¬ì¡°": [
            "Transformerì˜ Q, K, V í–‰ë ¬ì´ ê°ê° ë¬´ìŠ¨ ì—­í• ì„ í•˜ëŠ”ì§€ ìˆ˜ì‹ê³¼ í•¨ê»˜ ì„¤ëª…í•´ì¤˜",
            "Self-attentionì˜ ê³„ì‚° ë³µì¡ë„ê°€ O(nÂ²)ì¸ ì´ìœ ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜",
            "Multi-head attentionì—ì„œ í—¤ë“œë¥¼ ì—¬ëŸ¬ ê°œ ì“°ëŠ” ì´ìœ ê°€ ë­ì•¼?",
            "Scaled dot-product attentionì—ì„œ âˆšdkë¡œ ë‚˜ëˆ„ëŠ” ì´ìœ  ì„¤ëª…í•´ì¤˜"
        ],
        "Scaling Laws": [
            "Kaplan 2020 Scaling Lawsì—ì„œ compute-optimal í•™ìŠµì´ ë­”ì§€ ì„¤ëª…í•´ì¤˜",
            "íŒŒë¼ë¯¸í„° ìˆ˜ê°€ 2ë°° ëŠ˜ë©´ VRAMì€ ì–¼ë§ˆë‚˜ ë” í•„ìš”í•´? ê³„ì‚°í•´ì¤˜",
            "Chinchilla ë…¼ë¬¸ì´ GPT-3 í•™ìŠµ ë°©ì‹ì˜ ì–´ë–¤ ë¬¸ì œë¥¼ ì§€ì í–ˆì–´?",
            "7B ëª¨ë¸ì„ full precision(fp32)ìœ¼ë¡œ ë¡œë“œí•˜ë©´ VRAMì´ ì–¼ë§ˆë‚˜ í•„ìš”í•´?"
        ],
        "FlashAttention": [
            "FlashAttentionì´ naive attention ëŒ€ë¹„ ë©”ëª¨ë¦¬ë¥¼ ì¤„ì´ëŠ” í•µì‹¬ ì•„ì´ë””ì–´ê°€ ë­ì•¼?",
            "GPUì˜ HBMê³¼ SRAM ì°¨ì´ê°€ ë­ê³  ì™œ attentionì´ memory-boundì•¼?",
            "FlashAttentionì˜ tiling ë°©ì‹ì„ ìˆ˜ì‹ ì—†ì´ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜",
            "FlashAttention v2ì—ì„œ v1 ëŒ€ë¹„ ë­ê°€ ê°œì„ ëì–´?"
        ],
        "KV Cache": [
            "KV cacheê°€ ì—†ìœ¼ë©´ autoregressive generationì´ ì™œ ëŠë¦°ì§€ ì„¤ëª…í•´ì¤˜",
            "ëŒ€í™” ê¸¸ì´ê°€ 2ë°° ëŠ˜ë©´ KV cache ë©”ëª¨ë¦¬ëŠ” ì–¼ë§ˆë‚˜ ëŠ˜ì–´ë‚˜? ê³„ì‚°í•´ì¤˜",
            "Prefillê³¼ decode ë‹¨ê³„ì˜ ì°¨ì´ê°€ ë­ì•¼?",
            "ê¸´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ KV cacheê°€ VRAMì„ ì–¼ë§ˆë‚˜ ì°¨ì§€í•˜ëŠ”ì§€ llama-7b ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•´ì¤˜"
        ],
        "LoRA": [
            "LoRAì—ì„œ Wë¥¼ AÃ—Bë¡œ ë¶„í•´í•˜ëŠ” ìˆ˜í•™ì  ì§ê´€ì´ ë­ì•¼?",
            "rank=8 LoRAê°€ full fine-tuning ëŒ€ë¹„ trainable parameterë¥¼ ì–¼ë§ˆë‚˜ ì¤„ì—¬?",
            "LoRAë¥¼ attentionì˜ ì–´ëŠ í–‰ë ¬ì— ì ìš©í•˜ë©´ íš¨ê³¼ê°€ ê°€ì¥ í¬ê³  ì™œ?",
            "LoRA í•™ìŠµ í›„ ì¶”ë¡  ì‹œ ë³‘í•©í•˜ëŠ” ë°©ì‹ ì„¤ëª…í•´ì¤˜"
        ],
        "QLoRA": [
            "NF4 quantizationì´ int4 ëŒ€ë¹„ ì–´ë–¤ ì ì—ì„œ ë” ì¢‹ì•„?",
            "Double quantizationì´ ë­ê³  ë©”ëª¨ë¦¬ë¥¼ ì–¼ë§ˆë‚˜ ì ˆì•½í•´?",
            "7B ëª¨ë¸ì„ 4bitë¡œ ë¡œë“œí•˜ë©´ VRAMì´ ì–¼ë§ˆë‚˜ í•„ìš”í•´? 16bitì™€ ë¹„êµí•´ì¤˜",
            "Paged optimizerê°€ OOMì„ ì–´ë–»ê²Œ ë°©ì§€í•´?"
        ],
        "RLHF": [
            "RLHF íŒŒì´í”„ë¼ì¸ì˜ 3ë‹¨ê³„(SFTâ†’RMâ†’PPO)ë¥¼ ê°ê° ì„¤ëª…í•´ì¤˜",
            "Reward Modelì€ ì–´ë–»ê²Œ í•™ìŠµí•˜ê³  ë­˜ ì˜ˆì¸¡í•´?",
            "PPOê°€ RLHFì—ì„œ ì™œ ì‚¬ìš©ë˜ê³  KL divergenceëŠ” ì™œ í•„ìš”í•´?",
            "InstructGPT vs GPT-3 ì„±ëŠ¥ ì°¨ì´ê°€ ì™œ ë‚˜ëŠ”ì§€ alignment ê´€ì ì—ì„œ ì„¤ëª…í•´ì¤˜"
        ],
        "Mixture of Experts": [
            "MoEì—ì„œ routerê°€ expertë¥¼ ì„ íƒí•˜ëŠ” ë°©ì‹ì´ ì–´ë–»ê²Œ ë¼?",
            "Switch Transformerê°€ ê¸°ì¡´ MoE ëŒ€ë¹„ ë­˜ ë‹¨ìˆœí™”í–ˆì–´?",
            "7BÃ—8 MoE ëª¨ë¸(Mixtral)ì˜ active parameterê°€ ì‹¤ì œë¡œ ëª‡ Bì•¼?",
            "Dense 70B vs MoE 8Ã—7B: VRAMê³¼ ì¶”ë¡  ì†ë„ ë¹„êµí•´ì¤˜"
        ],
        "PagedAttention": [
            "vLLMì˜ PagedAttentionì´ ê¸°ì¡´ KV cache ë°©ì‹ì˜ ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•´?",
            "ë©”ëª¨ë¦¬ ë‹¨í¸í™”(fragmentation)ê°€ LLM servingì—ì„œ ì™œ ë¬¸ì œì•¼?",
            "Continuous batchingì´ static batching ëŒ€ë¹„ throughputì´ ë†’ì€ ì´ìœ ëŠ”?",
            "vLLMê³¼ TGI(Text Generation Inference) ì•„í‚¤í…ì²˜ ì°¨ì´ ì„¤ëª…í•´ì¤˜"
        ],
        "DeepSpeed ZeRO": [
            "ZeRO Stage 1, 2, 3ì˜ ì°¨ì´ë¥¼ íŒŒë¼ë¯¸í„°/ê·¸ë˜ë””ì–¸íŠ¸/ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜",
            "8ê°œ A100ì—ì„œ ZeRO-3ë¡œ 70B ëª¨ë¸ í•™ìŠµí•˜ë©´ GPUë‹¹ ë©”ëª¨ë¦¬ê°€ ì–¼ë§ˆë‚˜ í•„ìš”í•´?",
            "ZeRO-Infinityê°€ ZeRO-3ì™€ ë‹¤ë¥¸ ì ì´ ë­ì•¼?",
            "Gradient checkpointingê³¼ ZeROë¥¼ í•¨ê»˜ ì“¸ ë•Œ ì¥ë‹¨ì ì´ ë­ì•¼?"
        ],
        "Tensor Parallelism": [
            "Tensor parallelismì—ì„œ column-parallelê³¼ row-parallel linear layerê°€ ë­ì•¼?",
            "íŒŒì´í”„ë¼ì¸ ë³‘ë ¬í™”ì˜ bubble overheadê°€ ë­ê³  ì–´ë–»ê²Œ ì¤„ì—¬?",
            "ë°ì´í„°/í…ì„œ/íŒŒì´í”„ë¼ì¸ ë³‘ë ¬í™” ì¤‘ ì–¸ì œ ë­˜ ì¨ì•¼ í•´?",
            "Megatron-LMì—ì„œ 4-way tensor parallel ì„¤ì •í•˜ë©´ í†µì‹  ë¹„ìš©ì´ ì–¼ë§ˆë‚˜ ë°œìƒí•´?"
        ],
        "Cost Modeling": [
            "GPT-4 APIë¡œ ì›” 100ë§Œ í† í° ì“°ëŠ” ê²ƒ vs A10G self-host ë¹„ìš© ë¹„êµí•´ì¤˜",
            "7B ëª¨ë¸ì„ ë‹¨ì¼ A10G(24GB)ì—ì„œ ì„œë¹™í•  ë•Œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë™ì‹œ ìš”ì²­ ìˆ˜ëŠ”?",
            "íšŒì‚¬ì—ì„œ LLM self-host ê²°ì • ì‹œ ê³ ë ¤í•  TCO í•­ëª©ë“¤ ë‚˜ì—´í•´ì¤˜",
            "H100 vs A100 ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ (LLM inference ê¸°ì¤€)"
        ],
        "RAG": [
            "RAGê°€ fine-tuning ëŒ€ë¹„ hallucinationì„ ì¤„ì´ëŠ” ì›ë¦¬ê°€ ë­ì•¼?",
            "Chunk sizeë¥¼ ì–´ë–»ê²Œ ì •í•´ì•¼ í•´? ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ì–´ë–¤ ë¬¸ì œê°€ ìƒê²¨?",
            "Dense retrieval vs sparse retrieval (BM25) ì°¨ì´ì™€ ì–¸ì œ ë­˜ ì¨ì•¼ í•´?",
            "RAGì—ì„œ retrieval í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì§€í‘œê°€ ë­ì•¼?"
        ],
        "ReAct": [
            "ReActì˜ Thought-Action-Observation ë£¨í”„ë¥¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ì¤˜",
            "Chain-of-Thoughtì™€ ReActì˜ í•µì‹¬ ì°¨ì´ê°€ ë­ì•¼?",
            "ReActì—ì„œ tool callì´ ì‹¤íŒ¨í•˜ë©´ ì–´ë–»ê²Œ ì²˜ë¦¬í•´?",
            "ReAct íŒ¨í„´ì„ Claude APIë¡œ êµ¬í˜„í•˜ëŠ” ìµœì†Œ ì˜ˆì‹œ ì½”ë“œ ë³´ì—¬ì¤˜"
        ],
        "Tool Use & Planning": [
            "Toolformerê°€ tool ì‚¬ìš©ì„ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ ì„¤ëª…í•´ì¤˜",
            "OpenAI function calling vs Anthropic tool useì˜ êµ¬í˜„ ì°¨ì´ê°€ ë­ì•¼?",
            "LLMì´ ì–´ë–¤ toolì„ ì“¸ì§€ ê²°ì •í•˜ëŠ” ë°©ì‹ (routing) ì„¤ëª…í•´ì¤˜",
            "Tool use + RAGë¥¼ ê²°í•©í•œ agentic ì‹œìŠ¤í…œ ì„¤ê³„í•´ì¤˜"
        ],
        "ì „ì²´ ì„¤ê³„ í†µí•©": [
            "70B ëª¨ë¸ì„ 4bit ì–‘ìí™”í•´ì„œ vLLMìœ¼ë¡œ ì„œë¹™í•  ë•Œ í•„ìš”í•œ GPU ìŠ¤í™ ê³„ì‚°í•´ì¤˜",
            "AX ìš©ë„ë¡œ self-hosted LLM ì•„í‚¤í…ì²˜ ì„¤ê³„: ì‚¬ìš©ì 1000ëª…, p50 latency 2ì´ˆ ì´í•˜",
            "API vs self-host ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì–´ì¤˜ (ë¹„ìš©/ë ˆì´í„´ì‹œ/ë³´ì•ˆ ê¸°ì¤€)",
            "ë‚´ê°€ ë§Œë“¤ AX ì‹œìŠ¤í…œì˜ end-to-end ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ê·¸ë ¤ì¤˜ (í…ìŠ¤íŠ¸)"
        ]
    }

    return suggestions.get(topic, [
        f"{topic}ì˜ í•µì‹¬ ê°œë…ì„ ìˆ˜ì‹ê³¼ í•¨ê»˜ ì„¤ëª…í•´ì¤˜",
        f"{topic}ì„ ì‹¤ì œ ì½”ë“œë¡œ ì–´ë–»ê²Œ êµ¬í˜„í•´?",
        f"{topic}ì´ ì™œ ì¤‘ìš”í•œì§€, ì´ê²Œ ì—†ìœ¼ë©´ ì–´ë–¤ ë¬¸ì œê°€ ìƒê²¨?",
        f"{week_info.get('deliverable', 'í•™ìŠµ ê²°ê³¼ë¬¼')}ì„ ë§Œë“¤ê¸° ìœ„í•´ ë­ë¶€í„° ì‹œì‘í•´ì•¼ í•´?"
    ])


def run(input_data: dict, context: dict) -> Any:
    """í•™ìŠµ ì§„ë„ ì¶”ì  ì‹¤í–‰"""
    mode = input_data.get("mode", "daily")
    days_back = input_data.get("days_back", 1 if mode == "daily" else 7)
    override_week = input_data.get("override_week")
    workdir = context.get("workdir", str(Path(__file__).parent.parent))

    # 1. í•™ìŠµ ê³„íš ë¡œë“œ
    plan = load_study_plan()
    if not plan:
        return {
            "success": False,
            "error": f"study_plan.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {STUDY_PLAN_PATH}",
            "hint": "config/study_plan.jsonì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”"
        }

    # 2. í˜„ì¬ ì£¼ì°¨ ì •ë³´
    week_info = get_current_week_info(plan, override_week)

    # ì‹œì‘ ì „ì´ê±°ë‚˜ ì™„ë£Œëœ ê²½ìš° early return
    if week_info.get("status") in ("not_started", "completed", "unknown"):
        return {
            "success": True,
            "tracking": week_info
        }

    # 3. í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘
    prompts = collect_recent_prompts(days_back + 1, workdir)  # +1: ë‹¹ì¼ í¬í•¨

    # 4. ë ˆí¬íŠ¸ ìƒì„±
    tracking = build_study_report(mode, week_info, prompts, days_back)

    # 5. ëˆ„ì  ì§„ë„ (ì™„ë£Œëœ ì£¼ì°¨ ìš”ì•½)
    current_week = week_info["week"]
    if current_week > 1:
        completed_weeks = []
        week_kw_map = get_all_week_keywords(plan, current_week - 1)
        for w_num, kws in week_kw_map.items():
            # ì§€ë‚œ ì£¼ì°¨ì˜ í•™ìŠµ í”ì ì€ ì „ì²´ ê¸°ê°„ì—ì„œ ì²´í¬
            w_prompts = collect_recent_prompts(days_back + (current_week - w_num) * 7, workdir)
            w_matched, _ = detect_study_prompts(w_prompts, kws, "")
            completed_weeks.append({
                "week": w_num,
                "found_prompts": len(w_matched)
            })
        tracking["completed_weeks_summary"] = completed_weeks

    return {
        "success": True,
        "tracking": tracking
    }


def format_report_markdown(tracking: Dict) -> str:
    """íšŒê³  ë¦¬í¬íŠ¸ìš© ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ ìƒì„±"""
    lines = []
    lines.append("## ğŸ“š ML í•™ìŠµ ì§„ë„ ì²´í¬")
    lines.append("")

    status = tracking.get("status", "unknown")

    if status == "not_started":
        lines.append(f"â³ {tracking.get('message', '')}")
        return "\n".join(lines)

    if status == "completed":
        lines.append(f"ğŸ‰ {tracking.get('message', '16ì£¼ ì™„ë£Œ!')}")
        return "\n".join(lines)

    week = tracking.get("week", "?")
    topic = tracking.get("topic", "?")
    phase_name = tracking.get("phase_name", "?")
    week_range = tracking.get("week_range", "")
    goal = tracking.get("goal", "")
    deliverable = tracking.get("deliverable", "")

    lines.append(f"### Week {week}: {topic}")
    lines.append(f"**Phase {tracking.get('phase', '?')}**: {phase_name} | {week_range}")
    lines.append(f"**ë…¼ë¬¸**: {tracking.get('paper', '')}")
    lines.append(f"**ì´ë²ˆ ì£¼ ëª©í‘œ**: {goal}")
    lines.append(f"**ì‚°ì¶œë¬¼**: {deliverable}")
    lines.append("")

    # ê²½ê³ 
    warning = tracking.get("warning", {})
    lines.append(f"{warning.get('level', '')} {warning.get('message', '')}")
    lines.append("")

    # í•™ìŠµ ì¦ê±°
    evidence = tracking.get("study_evidence", {})
    matched = evidence.get("total_matched", 0)
    hq = evidence.get("high_quality_matched", 0)
    threshold = evidence.get("threshold", 0)
    lines.append(f"**í•™ìŠµ í”„ë¡¬í”„íŠ¸**: {matched}ê°œ ê°ì§€ (ê³ í’ˆì§ˆ: {hq}ê°œ / ëª©í‘œ: {threshold}ê°œ)")

    sample = evidence.get("sample_prompts", [])
    if sample:
        lines.append("")
        lines.append("**í•™ìŠµ í”ì  (ìƒìœ„ 3ê°œ)**:")
        for p in sample[:3]:
            kws = ", ".join(p.get("matched_keywords", []))
            content = p.get("content", "")[:80]
            lines.append(f'- [{p.get("source","")} {p.get("time","")}] "{content}" â†’ `{kws}`')

    # ì¶”ì²œ ì§ˆë¬¸
    suggestions = tracking.get("suggested_questions", [])
    if suggestions and matched < MIN_STUDY_PROMPTS_DAILY:
        lines.append("")
        lines.append("**ğŸ’¡ Codexì—ê²Œ ì´ë ‡ê²Œ ë¬¼ì–´ë³´ì„¸ìš”**:")
        for q in suggestions[:3]:
            lines.append(f'- "{q}"')

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description=TOOL_SPEC["description"])
    parser.add_argument("--tool-spec-json", action="store_true")
    parser.add_argument("--tool-input-json", type=str)
    parser.add_argument("--tool-context-json", type=str, default="{}")
    args = parser.parse_args()

    if args.tool_spec_json:
        print(json.dumps(TOOL_SPEC, ensure_ascii=False, indent=2))
        return

    if not args.tool_input_json:
        input_data = {}
    else:
        input_data = json.loads(args.tool_input_json)

    context = json.loads(args.tool_context_json)
    result = run(input_data, context)

    # CLI ì¶œë ¥ ì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ë„ í•¨ê»˜ ì¶œë ¥
    tracking = result.get("tracking", {})
    if tracking and tracking.get("status") == "active":
        print(format_report_markdown(tracking))
        print("")
        print("---")
        print("(JSON ìƒì„¸)")

    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
