from __future__ import annotations

import json
import os
import re
from typing import Any


def is_tool_list_request(text: str) -> bool:
    normalized = text.strip().lower()
    if normalized.startswith("/tool "):
        return False
    if normalized in {"/tools", "tools", "tool list", "ë„êµ¬ ëª©ë¡", "íˆ´ ëª©ë¡", "ë„êµ¬ë¦¬ìŠ¤íŠ¸", "íˆ´ë¦¬ìŠ¤íŠ¸"}:
        return True
    return any(keyword in normalized for keyword in ("tool list", "ë„êµ¬ ëª©ë¡", "íˆ´ ëª©ë¡", "ë„êµ¬ ë¦¬ìŠ¤íŠ¸", "íˆ´ ë¦¬ìŠ¤íŠ¸"))


def is_schedule_list_request(text: str) -> bool:
    normalized = text.strip().lower()
    if normalized in {"/schedules", "schedules", "schedule list", "ìŠ¤ì¼€ì¤„ ëª©ë¡", "ì¼ì • ëª©ë¡"}:
        return True
    return any(keyword in normalized for keyword in ("schedule list", "ìŠ¤ì¼€ì¤„ ëª©ë¡", "ì¼ì • ëª©ë¡"))


def format_tool_list(executor: Any) -> str:
    lines = [f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ (custom dir: {executor.custom_tool_dir}):"]
    for item in executor.describe_tools():
        required = ", ".join(item["required"]) if item["required"] else "-"
        file_hint = f", íŒŒì¼: {item['file']}" if item.get("file") else ""
        lines.append(f"- {item['name']} [{item['source']}]: {item['description']} (í•„ìˆ˜: {required}{file_hint})")
    if executor.load_errors:
        lines.append("")
        lines.append("ë¡œë“œ ì‹¤íŒ¨í•œ ì»¤ìŠ¤í…€ ë„êµ¬:")
        for err in executor.load_errors:
            lines.append(f"- {err}")
    lines.append("")
    lines.append("ì§ì ‘ ì‹¤í–‰ ì˜ˆì‹œ: /tool list_files {\"path\":\".\"}")
    lines.append("íŒŒì¼ ì½ê¸° ì˜ˆì‹œ: /tool read_text_file {\"path\":\"tools/add_two_numbers.py\"}")
    lines.append("íŒŒì¼ ì €ì¥ ì˜ˆì‹œ: /tool save_text_file {\"path\":\"tools/my_tool.py\",\"content\":\"...\"}")
    lines.append("ì»¤ìŠ¤í…€ ì¡°íšŒ ì˜ˆì‹œ: /tool list_custom_tools {}")
    lines.append("íŒŒì¼ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì˜ˆì‹œ: /tool tool_registry_status {}")
    lines.append("ì»¤ìŠ¤í…€ ì‚­ì œ ì˜ˆì‹œ: /tool delete_custom_tool_file {\"file_name\":\"my_tool.py\"}")
    lines.append(
        "ìŠ¤ì¼€ì¤„ ë“±ë¡ ì˜ˆì‹œ: /tool schedule_daily_tool {\"tool_name\":\"echo_tool\",\"time\":\"09:00\",\"tool_input\":{\"text\":\"daily\"}}"
    )
    lines.append("ìŠ¤ì¼€ì¤„ ëª©ë¡ ì˜ˆì‹œ: /schedules")
    lines.append("arXiv ì¼ì¼ ìŠ¤ì¼€ì¤„ ì˜ˆì‹œ: /schedule-arxiv 08:00 deepseek llm")
    lines.append("Semantic snapshot ì˜ˆì‹œ: /tool semantic_web_snapshot {\"url\":\"https://arxiv.org\"}")
    lines.append("ì˜¨ì²´ì¸ ì¡°íšŒ ì˜ˆì‹œ: /tool onchain_wallet_snapshot {\"network\":\"ethereum\",\"address\":\"0x...\"}")
    lines.append("í…”ë ˆê·¸ë¨ ì „ì†¡ ì˜ˆì‹œ: /tool telegram_send_message {\"text\":\"ì•ˆë…•í•˜ì„¸ìš”\"}")
    lines.append("ì¬ë™ê¸°í™” ì˜ˆì‹œ: /sync-tools")
    return "\n".join(lines)


def parse_tool_command(text: str) -> tuple[str, dict[str, Any]] | None:
    if not text.startswith("/tool "):
        return None
    payload = text[len("/tool ") :].strip()
    if not payload:
        raise ValueError("ì‚¬ìš©ë²•: /tool <tool_name> <json_input(optional)>")

    parts = payload.split(maxsplit=1)
    tool_name = parts[0].strip()
    if not tool_name:
        raise ValueError("ë„êµ¬ ì´ë¦„(tool_name)ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")

    if len(parts) == 1:
        return tool_name, {}

    raw_json = parts[1].strip()
    if not raw_json:
        return tool_name, {}
    try:
        parsed = json.loads(raw_json)
    except json.JSONDecodeError as exc:
        raise ValueError(f"JSON ì…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {exc}") from exc
    if not isinstance(parsed, dict):
        raise ValueError("ë„êµ¬ ì…ë ¥ JSONì€ ê°ì²´(object)ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    return tool_name, parsed


def parse_tool_only_mode_command(text: str) -> bool | None:
    normalized = text.strip().lower()
    if normalized in {"/tool-only on", "/toolonly on", "tool-only on", "tool only on", "ë„êµ¬ë§Œ on"}:
        return True
    if normalized in {"/tool-only off", "/toolonly off", "tool-only off", "tool only off", "ë„êµ¬ë§Œ off"}:
        return False
    if normalized in {
        "/tool-only",
        "/toolonly",
        "ë„êµ¬ë§Œ ì‚¬ìš©",
        "ì•ìœ¼ë¡œ ë„êµ¬ë§Œ ì‚¬ìš©í•´ì„œ ë‹µí•´",
        "ì•ìœ¼ë¡œ ë„êµ¬ë§Œ ì‚¬ìš©í•´ì„œ ë‹µí•˜ê±°ë¼",
    }:
        return True
    if any(token in normalized for token in ("ë„êµ¬ë§Œ í•´ì œ", "ë„êµ¬ ì „ìš© í•´ì œ", "tool only off", "disable tool-only")):
        return False
    return None


def parse_set_permission_command(text: str) -> tuple[str, str] | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/set-permission "):
        return None
    parts = normalized.split()
    if len(parts) != 3:
        raise ValueError("ì‚¬ìš©ë²•: /set-permission <tool_name> <allow|prompt|deny>")
    tool_name = parts[1].strip()
    mode = parts[2].strip().lower()
    if not tool_name:
        raise ValueError("tool_name ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if mode not in {"allow", "prompt", "deny"}:
        raise ValueError("ê¶Œí•œ ëª¨ë“œëŠ” allow/prompt/deny ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    return tool_name, mode


def parse_memory_command(text: str) -> dict[str, Any] | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/memory"):
        return None
    parts = normalized.split(maxsplit=2)
    if len(parts) == 1:
        return {"action": "status"}
    action = parts[1].strip().lower()
    if action == "status":
        return {"action": "status"}
    if action == "latest":
        count = 5
        if len(parts) >= 3 and parts[2].strip():
            try:
                count = int(parts[2].strip())
            except ValueError as exc:
                raise ValueError("ì‚¬ìš©ë²•: /memory latest <count> (countëŠ” ìˆ«ì)") from exc
        return {"action": "latest", "count": max(1, min(count, 50))}
    if action == "query":
        if len(parts) < 3 or not parts[2].strip():
            raise ValueError("ì‚¬ìš©ë²•: /memory query <text>")
        return {"action": "query", "text": parts[2].strip()}
    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” memory ëª…ë ¹ì…ë‹ˆë‹¤. (/memory status|latest|query)")


def parse_reflexion_command(text: str) -> dict[str, Any] | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/reflexion"):
        return None
    parts = normalized.split(maxsplit=2)
    if len(parts) == 1:
        return {"action": "status"}
    action = parts[1].strip().lower()
    if action == "status":
        return {"action": "status"}
    if action == "latest":
        count = 10
        if len(parts) >= 3 and parts[2].strip():
            try:
                count = int(parts[2].strip())
            except ValueError as exc:
                raise ValueError("ì‚¬ìš©ë²•: /reflexion latest <count> (countëŠ” ìˆ«ì)") from exc
        return {"action": "latest", "count": max(1, min(count, 100))}
    if action == "query":
        if len(parts) < 3 or not parts[2].strip():
            raise ValueError("ì‚¬ìš©ë²•: /reflexion query <text>")
        return {"action": "query", "text": parts[2].strip()}
    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” reflexion ëª…ë ¹ì…ë‹ˆë‹¤. (/reflexion status|latest|query)")


def parse_feedback_command(text: str) -> str | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/feedback"):
        return None
    payload = normalized[len("/feedback") :].strip()
    if not payload:
        raise ValueError("ì‚¬ìš©ë²•: /feedback <í”¼ë“œë°± ë‚´ìš©>")
    return payload


def parse_delegate_command(text: str) -> str | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/delegate"):
        return None
    payload = normalized[len("/delegate") :].strip()
    if not payload:
        raise ValueError("ì‚¬ìš©ë²•: /delegate <ìš”ì²­>")
    return payload


def parse_schedule_arxiv_command(text: str) -> dict[str, Any] | None:
    normalized = text.strip()
    if not normalized.lower().startswith("/schedule-arxiv"):
        return None
    parts = normalized.split(maxsplit=2)
    if len(parts) < 2:
        raise ValueError("ì‚¬ìš©ë²•: /schedule-arxiv <HH:MM> [keywords...]")
    hhmm = parts[1].strip()
    if not re.fullmatch(r"(?:[01]\d|2[0-3]):[0-5]\d", hhmm):
        raise ValueError("ì‹œê°„ í˜•ì‹ì€ HH:MM ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: /schedule-arxiv 08:00 deepseek llm")
    keywords: list[str] = []
    if len(parts) >= 3 and parts[2].strip():
        raw = parts[2].strip().replace(",", " ")
        for token in raw.split():
            t = token.strip()
            if t and t not in keywords:
                keywords.append(t)
    if not keywords:
        keywords = ["llm"]
    return {"time": hhmm, "keywords": keywords}


def parse_arxiv_quick_request(text: str) -> dict[str, Any] | None:
    normalized = text.strip()
    if not normalized:
        return None
    lowered = normalized.lower()
    source_tokens = ("arxiv", "ì•„ì¹´ì´ë¸Œ")
    topic_tokens = ("ë…¼ë¬¸", "paper", "papers")
    action_tokens = (
        "ìš”ì•½",
        "ì°¾",
        "ê²€ìƒ‰",
        "ê°€ì ¸",
        "ì •ë¦¬",
        "ë³´ì—¬",
        "ë¶ˆëŸ¬",
        "ë‹¤ìš´ë¡œë“œ",
        "ì•Œë ¤",
        "list",
        "fetch",
        "search",
        "summar",
        "download",
    )
    if not any(token in lowered for token in action_tokens):
        return None
    if not any(token in lowered for token in source_tokens + topic_tokens):
        return None

    count_match = re.search(r"(\d+)\s*(ê°œ|í¸|papers?)", normalized, re.IGNORECASE)
    if count_match is None:
        count_match = re.search(r"\b(\d+)\b", normalized)
    max_papers = 3
    if count_match:
        try:
            max_papers = int(count_match.group(1))
        except ValueError:
            max_papers = 3
    max_papers = max(1, min(max_papers, 20))

    if "ì˜¤ëŠ˜" in normalized or "today" in lowered:
        days_back = 1
    elif "ì–´ì œ" in normalized or "yesterday" in lowered:
        days_back = 2
    elif any(token in lowered for token in ("ì˜ˆì „", "ê³¼ê±°", "ì˜›", "ì´ì „", "ì§€ë‚œ", "old", "older", "historical")):
        days_back = 3650
    elif any(token in lowered for token in ("ìµœê·¼", "ìµœì‹ ", "latest", "recent")):
        days_back = 14
    else:
        days_back = 365

    keywords: list[str] = []
    keyword_map = {
        "deepseek": "deepseek",
        "deep seek": "deepseek",
        "ë”¥ì‹œí¬": "deepseek",
        "llm": "llm",
        "ë¨¸ì‹ ëŸ¬ë‹": "machine learning",
        "machine learning": "machine learning",
        "ê°•í™”í•™ìŠµ": "reinforcement learning",
        "vision": "computer vision",
        "ì»´í“¨í„°ë¹„ì „": "computer vision",
        "nlp": "nlp",
    }
    for trigger, mapped in keyword_map.items():
        if trigger in lowered and mapped not in keywords:
            keywords.append(mapped)

    quoted = re.findall(r"['\"]([^'\"]{2,80})['\"]", normalized)
    for phrase in quoted:
        term = phrase.strip()
        if term and term not in keywords:
            keywords.append(term)

    payload: dict[str, Any] = {
        "max_papers": max_papers,
        "days_back": days_back,
        "output": "text",
    }
    if keywords:
        payload["keywords"] = keywords
    return payload


def summarize_for_memory(text: str, max_chars: int = 220) -> str:
    normalized = " ".join(text.split())
    if len(normalized) <= max_chars:
        return normalized
    return normalized[: max_chars - 3] + "..."


def _bool_env_local(name: str, default: bool = False) -> bool:
    raw = (os.getenv(name) or "").strip().lower()
    if not raw:
        return default
    return raw in {"1", "true", "yes", "on"}


def _float_env_local(name: str, default: float = 0.0) -> float:
    raw = (os.getenv(name) or "").strip()
    if not raw:
        return default
    try:
        return float(raw)
    except ValueError:
        return default


def _try_parse_json(text: str) -> Any | None:
    body = text.strip()
    if not body:
        return None
    try:
        return json.loads(body)
    except json.JSONDecodeError:
        return None


def format_user_output(text: str) -> str:
    parsed = _try_parse_json(text)
    if parsed is None:
        return text

    if isinstance(parsed, dict):
        error = parsed.get("error")
        if isinstance(error, str) and error.strip():
            return f"ì˜¤ë¥˜: {error}"

        summary = parsed.get("summary")
        if isinstance(summary, str) and summary.strip():
            return summary

        nested_result = parsed.get("result")
        if isinstance(nested_result, str) and nested_result.strip():
            nested = _try_parse_json(nested_result)
            if isinstance(nested, dict):
                nested_error = nested.get("error")
                if isinstance(nested_error, str) and nested_error.strip():
                    return f"ì˜¤ë¥˜: {nested_error}"
                nested_summary = nested.get("summary")
                if isinstance(nested_summary, str) and nested_summary.strip():
                    return nested_summary
                return json.dumps(nested, ensure_ascii=False, indent=2)
            return nested_result

        return json.dumps(parsed, ensure_ascii=False, indent=2)

    if isinstance(parsed, list):
        return json.dumps(parsed, ensure_ascii=False, indent=2)
    return str(parsed)


def format_permissions_map(permissions: dict[str, str]) -> str:
    if not permissions:
        return "í˜„ì¬ ëª…ì‹œëœ ë„êµ¬ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. (ê¸°ë³¸ê°’: allow)"
    lines = ["í˜„ì¬ ë„êµ¬ ê¶Œí•œ ì •ì±…:"]
    for name in sorted(permissions.keys()):
        lines.append(f"- {name}: {permissions[name]}")
    lines.append("ë³€ê²½ ì˜ˆì‹œ: /set-permission run_shell deny")
    return "\n".join(lines)


def format_memory_query_result(query: str, items: list[dict[str, Any]]) -> str:
    if not items:
        return f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {query}"
    lines = [f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼ ({len(items)}ê±´): {query}"]
    for idx, item in enumerate(items, start=1):
        score = float(item.get("score", 0.0) or 0.0)
        role = str(item.get("role", ""))
        ts = str(item.get("ts", ""))
        summary = str(item.get("summary", ""))
        lines.append(f"{idx}. [{role}] score={score:.3f} ts={ts}")
        lines.append(f"   {summary}")
    return "\n".join(lines)


def format_reflexion_records(items: list[dict[str, Any]]) -> str:
    if not items:
        return "ë¦¬í”Œë ‰ì…˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
    lines = [f"ë¦¬í”Œë ‰ì…˜ ìµœê·¼ ê¸°ë¡ ({len(items)}ê±´):"]
    for idx, item in enumerate(items, start=1):
        row_type = str(item.get("type", ""))
        kind = str(item.get("kind", ""))
        ts = str(item.get("ts", ""))
        source = str(item.get("source", ""))
        text = str(item.get("text", item.get("outcome", ""))).strip()
        if len(text) > 140:
            text = text[:137] + "..."
        label = f"{row_type}/{kind}" if kind else row_type
        lines.append(f"{idx}. [{label}] ts={ts} source={source}")
        if text:
            lines.append(f"   {text}")
    return "\n".join(lines)


def parse_context_command(text: str) -> dict[str, Any] | None:
    """
    /context [minutes] ëª…ë ¹ì–´ íŒŒì‹±

    ì˜ˆì‹œ:
    - /context
    - /context 60
    """
    normalized = text.strip()
    if not normalized.lower().startswith("/context"):
        return None

    payload = normalized[len("/context"):].strip()

    result = {}
    if payload and payload.isdigit():
        result["lookback_minutes"] = int(payload)

    return result


def parse_today_command(text: str) -> dict[str, Any] | None:
    """
    /today [keyword] ëª…ë ¹ì–´ íŒŒì‹±

    ì˜ˆì‹œ:
    - /today
    - /today BoramClaw
    """
    normalized = text.strip()
    if not normalized.lower().startswith("/today"):
        return None

    payload = normalized[len("/today"):].strip()

    result = {"mode": "daily"}
    if payload:
        result["focus_keyword"] = payload

    return result


def parse_week_command(text: str) -> dict[str, Any] | None:
    """
    /week [keyword] ëª…ë ¹ì–´ íŒŒì‹±

    ì˜ˆì‹œ:
    - /week
    - /week Claude
    """
    normalized = text.strip()
    if not normalized.lower().startswith("/week"):
        return None

    payload = normalized[len("/week"):].strip()

    result = {"mode": "weekly"}
    if payload:
        result["focus_keyword"] = payload

    return result


def format_workday_recap(report_data: dict[str, Any]) -> str:
    """
    workday_recap íˆ´ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        report_data: workday_recapì˜ run() ê²°ê³¼

    Returns:
        í¬ë§·ëœ ë¬¸ìì—´
    """
    if report_data.get("status") != "success":
        error = report_data.get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        return f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {error}"

    report = report_data.get("report", {})
    mode = report.get("mode", "daily")
    period_label = "ì˜¤ëŠ˜" if mode == "daily" else "ì´ë²ˆ ì£¼"
    summary = report.get("summary", "")
    sections = report.get("sections", {})
    errors = report.get("errors", [])

    lines = [
        f"ğŸ“Š {period_label} ê°œë°œ í™œë™ ë¦¬í¬íŠ¸",
        f"ìƒì„± ì‹œê°„: {report.get('generated_at', 'N/A')}",
        "",
        f"âœ¨ {summary}",
        "",
    ]

    # Git ì„¹ì…˜
    if "git" in sections:
        git = sections["git"]
        commits = git.get("total_commits", 0)
        if commits > 0:
            lines.append("### ğŸ“ Git í™œë™")
            lines.append(f"- ì»¤ë°‹: {commits}ê°œ")
            lines.append(f"- ë³€ê²½: +{git.get('insertions', 0)} -{git.get('deletions', 0)} (íŒŒì¼ {git.get('files_changed', 0)}ê°œ)")

            authors = git.get("authors", [])
            if authors:
                author_names = ", ".join(authors[:3])
                lines.append(f"- ì‘ì„±ì: {author_names}")

            branches = git.get("active_branches", [])
            if branches:
                branch_names = ", ".join(branches[:3])
                lines.append(f"- í™œì„± ë¸Œëœì¹˜: {branch_names}")
            lines.append("")

    # Shell ì„¹ì…˜
    if "shell" in sections:
        shell = sections["shell"]
        total_cmds = shell.get("total_commands", 0)
        if total_cmds > 0:
            lines.append("### ğŸ’» Shell í™œë™")
            lines.append(f"- ëª…ë ¹ì–´ ì‹¤í–‰: {total_cmds}ê°œ (ìœ ë‹ˆí¬: {shell.get('unique_commands', 0)}ê°œ)")

            top_commands = shell.get("top_commands", [])
            if top_commands:
                lines.append("- ìì£¼ ì“´ ëª…ë ¹ì–´:")
                for cmd_info in top_commands[:5]:
                    if isinstance(cmd_info, dict):
                        cmd = cmd_info.get("command", "")
                        count = cmd_info.get("count", 0)
                        lines.append(f"  â€¢ {cmd}: {count}íšŒ")

            alias_suggestions = shell.get("alias_suggestions", [])
            if alias_suggestions:
                lines.append("- Alias ì¶”ì²œ:")
                for suggestion in alias_suggestions[:3]:
                    if isinstance(suggestion, dict):
                        cmd = suggestion.get("command", "")
                        count = suggestion.get("count", 0)
                        lines.append(f"  â€¢ {cmd} ({count}íšŒ)")
            lines.append("")

    # Browser ì„¹ì…˜
    if "browser" in sections:
        browser = sections["browser"]
        visits = browser.get("total_visits", 0)
        if visits > 0:
            lines.append("### ğŸŒ Browser í™œë™")
            lines.append(f"- ë°©ë¬¸: {visits}ê°œ í˜ì´ì§€ (ë„ë©”ì¸ {browser.get('unique_domains', 0)}ê°œ)")
            lines.append(f"- ì„¸ì…˜: {browser.get('sessions', 0)}ê°œ")

            top_domains = browser.get("top_domains", [])
            if top_domains:
                lines.append("- ìì£¼ ë°©ë¬¸í•œ ë„ë©”ì¸:")
                for domain_info in top_domains[:5]:
                    if isinstance(domain_info, dict):
                        domain = domain_info.get("domain", "")
                        count = domain_info.get("count", 0)
                        lines.append(f"  â€¢ {domain}: {count}íšŒ")
            lines.append("")

    # Screen ì„¹ì…˜
    if "screen" in sections:
        screen = sections["screen"]
        captures = screen.get("total_captures", 0)
        if captures > 0:
            lines.append("### ğŸ–¥ï¸  Screen í™œë™ (screenpipe)")
            lines.append(f"- ìº¡ì²˜: {captures}ê°œ")

            focus_keyword = screen.get("focus_keyword")
            if focus_keyword:
                lines.append(f"- ê²€ìƒ‰ í‚¤ì›Œë“œ: '{focus_keyword}'")

            top_apps = screen.get("top_apps", [])
            if top_apps:
                lines.append("- ìì£¼ ì‚¬ìš©í•œ ì•±:")
                for app_name, count in top_apps[:5]:
                    lines.append(f"  â€¢ {app_name}: {count}íšŒ")
            lines.append("")

    # ì—ëŸ¬ ì„¹ì…˜
    if errors:
        lines.append("### âš ï¸  ê²½ê³ ")
        for err in errors:
            lines.append(f"- {err}")
        lines.append("")

    return "\n".join(lines)
